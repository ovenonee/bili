#!/usr/bin/env python
# coding: utf-8

# In[31]:


# ==================== å•å…ƒæ ¼1ï¼šå¼ºåˆ¶NVIDIA GPU ====================
import sys
import os
sys.stdout.flush()
os.environ['PYTHONUNBUFFERED'] = '1'

from torch.utils.data import Dataset
import pandas as pd
import torch
from torchvision import transforms
from PIL import Image
import numpy as np
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
import torch.nn.functional as F
import matplotlib.pyplot as plt
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")

# âœ… å…³é”®ä¿®å¤ï¼šåˆ—å‡ºæ‰€æœ‰GPUï¼Œå¼ºåˆ¶é€‰NVIDIA
if torch.cuda.is_available():
    gpu_count = torch.cuda.device_count()
    print(f"\næ£€æµ‹åˆ° {gpu_count} ä¸ªCUDAè®¾å¤‡:")

    for i in range(gpu_count):
        name = torch.cuda.get_device_name(i)
        print(f"  cuda:{i}: {name}")

        # è‡ªåŠ¨é€‰æ‹©NVIDIAï¼ˆåç§°åŒ…å«"GeForce"æˆ–"RTX"ï¼‰
        if "GeForce" in name or "RTX" in name:
            device = torch.device(f"cuda:{i}")
            print(f"\nâœ… å·²é€‰æ‹©NVIDIA GPU: cuda:{i}")
            break
    else:
        # å¦‚æœæ²¡æ‰¾åˆ°NVIDIAï¼Œç”¨ç¬¬ä¸€ä¸ª
        device = torch.device("cuda:0")
        print(f"\nâš ï¸ æœªè¯†åˆ«NVIDIAï¼Œé»˜è®¤ä½¿ç”¨: cuda:0")
else:
    device = torch.device("cpu")
    print(f"\nâŒ æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPU")

# æ‰“å°æœ€ç»ˆè®¾å¤‡
print(f"\næœ€ç»ˆè®¾å¤‡: {device}")
print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name(device) if device.type=='cuda' else 'CPU'}")
# ==================== å•å…ƒæ ¼1æœ«å°¾æ·»åŠ  ====================
# éªŒè¯å¯¼å…¥æ˜¯å¦æˆåŠŸ
print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"âœ… è®¾å¤‡: {device}")

# éªŒè¯transformsæ˜¯å¦å¯ç”¨
try:
    _test = transforms.Compose([transforms.ToTensor()])
    print("âœ… transformså¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ transformså¯¼å…¥å¤±è´¥: {e}")

print("\nğŸ“ è¯·ç¡®è®¤ä»¥ä¸Š3è¡Œéƒ½æ˜¾ç¤ºâœ…åå†æ‰§è¡Œå•å…ƒæ ¼2")


# In[23]:


# ==================== å•å…ƒæ ¼2ï¼šè®­ç»ƒé…ç½® ====================
# å…³é”®ä¿®æ”¹ï¼šæ‰€æœ‰é…ç½®å‚æ•°é›†ä¸­åˆ°ä¸€å¤„ï¼Œtransformå®šä¹‰åœ¨å…¨å±€ä½œç”¨åŸŸ

# è·¯å¾„é…ç½®ï¼ˆæ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
CSV_PATH = r"D:\bilitest\merged_data\merged_data.csv"
IMAGE_PATH = r"D:\bilitest\merged_data\covers"
MODEL_SAVE_PATH = r"D:\bilitest"

# è¶…å‚æ•°
batch_size = 32
EPOCHS = 10
LEARNING_RATE = 0.01

# å½’ä¸€åŒ–å‚æ•°
MAX_PLAY = 100_000_000
MAX_LIKE = 100_000_000

# æ•°æ®é¢„å¤„ç†ï¼ˆå…³é”®ï¼šå¿…é¡»åœ¨Datasetç±»å¤–éƒ¨å®šä¹‰ï¼‰
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# åå½’ä¸€åŒ–ï¼ˆå¯è§†åŒ–ç”¨ï¼‰
denormalize = transforms.Normalize(
    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
    std=[1/0.229, 1/0.224, 1/0.225]
)

print("âœ… é…ç½®åŠ è½½å®Œæˆ")


# In[24]:


# ==================== å•å…ƒæ ¼3ï¼šæ•°æ®é›†ç±»å®šä¹‰ ====================
# å…³é”®ä¿®æ”¹ï¼šæ˜¾å¼è½¬æ¢RGBæ ¼å¼ï¼Œä¿®å¤å›¾ç‰‡å°ºå¯¸ä¸ä¸€è‡´å¯¼è‡´çš„stacké”™è¯¯

class VideoCoverDataset(Dataset):
    def __init__(self, csv_path, img_dir, transform=None, is_train=True):
        """åˆå§‹åŒ–æ•°æ®é›†"""
        # åŠ è½½CSV
        try:
            self.data = pd.read_csv(csv_path)
            print(f"âœ… CSVåŠ è½½æˆåŠŸ: {len(self.data)} è¡Œ")
        except Exception as e:
            print(f"âŒ CSVåŠ è½½å¤±è´¥: {e}")
            raise

        # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        train_size = int(0.8 * len(self.data))
        if is_train:
            self.data = self.data[:train_size]
        else:
            self.data = self.data[train_size:]

        # æ£€æŸ¥å¿…è¦åˆ—
        required_cols = ['filename', 'play_count', 'like_count']
        missing_cols = [col for col in required_cols if col not in self.data.columns]
        if missing_cols:
            raise ValueError(f"CSVç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")

        self.img_dir = img_dir
        self.transform = transform

        print(f"ğŸ“Š {'è®­ç»ƒ' if is_train else 'æµ‹è¯•'}é›†å¤§å°: {len(self.data)}")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        """åŠ è½½å•æ¡æ•°æ®"""
        row = self.data.iloc[idx]

        # å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶è½¬ä¸ºRGBä¸‰é€šé“ï¼Œé¿å…æ¨¡å¼ä¸ä¸€è‡´
        img_path = os.path.join(self.img_dir, str(row['filename']))
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"ğŸ”¥ å›¾ç‰‡åŠ è½½å¤±è´¥: {img_path} - é”™è¯¯: {e}")
            # è¿”å›é»‘è‰²å ä½å›¾
            image = Image.new('RGB', (256, 256), color='black')

        # åº”ç”¨transformï¼ˆResize+ToTensor+Normalizeï¼‰
        if self.transform:
            image = self.transform(image)

        # æ ‡ç­¾å½’ä¸€åŒ–ï¼ˆå¯¹æ•°å˜æ¢ï¼‰
        play = np.log1p(row['play_count']) / np.log1p(MAX_PLAY)
        like = np.log1p(row['like_count']) / np.log1p(MAX_LIKE)
        target = torch.tensor([play, like], dtype=torch.float32)

        return image, target


# In[25]:


# ==================== å•å…ƒæ ¼4ï¼šæ•°æ®åŠ è½½éªŒè¯ ====================
# å…³é”®ä¿®æ”¹ï¼šnum_workers=0ï¼ˆWindowså…¼å®¹ï¼‰ï¼Œæ‰“å°loaderä¿¡æ¯ç¡®è®¤æ•°æ®ä¸ä¸ºç©º

print("ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®...")
from torch.utils.data import DataLoader
# å®ä¾‹åŒ–æ•°æ®é›†ï¼ˆä¼ å…¥transformï¼‰
train_dataset = VideoCoverDataset(CSV_PATH, IMAGE_PATH, transform=transform, is_train=True)
test_dataset = VideoCoverDataset(CSV_PATH, IMAGE_PATH, transform=transform, is_train=False)

# åˆ›å»ºDataLoader
train_loader = DataLoader(
    train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=0,  # å…³é”®ï¼šWindowsä¸‹å¿…é¡»è®¾ä¸º0
    pin_memory=True if torch.cuda.is_available() else False
)
test_loader = DataLoader(
    test_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=0
)

# éªŒè¯æ•°æ®åŠ è½½
print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆï¼")
print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ¡ â†’ {len(train_loader)} ä¸ªbatch")
print(f"   æµ‹è¯•é›†: {len(test_dataset)} æ¡ â†’ {len(test_loader)} ä¸ªbatch")

# æµ‹è¯•è¯»å–ç¬¬ä¸€ä¸ªbatch
print("\nğŸ” æµ‹è¯•è¯»å–ç¬¬ä¸€ä¸ªbatch...")
for imgs, targets in train_loader:
    print(f"   å›¾ç‰‡å½¢çŠ¶: {imgs.shape} (batch, é€šé“, é«˜, å®½)")
    print(f"   æ ‡ç­¾å½¢çŠ¶: {targets.shape} (batch, 2)")
    break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªbatch


# In[32]:


# ==================== å•å…ƒæ ¼5ï¼šæ¨¡å‹å®šä¹‰ ====================
# å…³é”®ä¿®æ”¹ï¼šåˆ é™¤åŠ¨æ€è®¡ç®—ç»´åº¦ï¼Œç›´æ¥ç¡¬ç¼–ç 338272ï¼ˆé¿å…åˆå§‹åŒ–æ—¶å¼•ç”¨æœªå®šä¹‰çš„netï¼‰

class InceptionA(torch.nn.Module):
    """Inceptionæ¨¡å—"""
    def __init__(self, in_channel):
        super().__init__()
        # åˆ†æ”¯1ï¼šå¹³å‡æ± åŒ– + 1x1å·ç§¯
        self.branch_pool = torch.nn.Conv2d(in_channel, 24, kernel_size=1)

        # åˆ†æ”¯2ï¼š1x1å·ç§¯
        self.branch1x1 = torch.nn.Conv2d(in_channel, 16, kernel_size=1)

        # åˆ†æ”¯3ï¼š5x5å·ç§¯ (1x1é™ç»´ â†’ 5x5å·ç§¯)
        self.branch5x5_1 = torch.nn.Conv2d(in_channel, 16, kernel_size=1)
        self.branch5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2)

        # åˆ†æ”¯4ï¼š3x3å·ç§¯ (1x1é™ç»´ â†’ 3x3å·ç§¯ â†’ 3x3å·ç§¯)
        self.branch3x3_1 = torch.nn.Conv2d(in_channel, 16, kernel_size=1)
        self.branch3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1)
        self.branch3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1)

    def forward(self, x):
        # å¹¶è¡Œå¤„ç†4ä¸ªåˆ†æ”¯
        branch_pool = self.branch_pool(F.avg_pool2d(x, kernel_size=3, padding=1, stride=1))
        branch1x1 = self.branch1x1(x)
        branch5x5 = self.branch5x5_2(self.branch5x5_1(x))
        branch3x3 = self.branch3x3_3(self.branch3x3_2(self.branch3x3_1(x)))

        # åœ¨é€šé“ç»´åº¦æ‹¼æ¥
        outputs = [branch_pool, branch1x1, branch3x3, branch5x5]
        return torch.cat(outputs, dim=1)  # è¾“å‡ºé€šé“: 24+16+24+24 = 88

class Net(torch.nn.Module):
    """ä¸»ç½‘ç»œ"""
    def __init__(self):
        super().__init__()
        # ç‰¹å¾æå–
        self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=5)
        self.inception1 = InceptionA(in_channel=10)

        self.conv2 = torch.nn.Conv2d(88, 20, kernel_size=5)
        self.inception2 = InceptionA(in_channel=20)

        self.pooling = torch.nn.MaxPool2d(2)

        # âœ… å…³é”®ä¿®æ”¹ï¼šç¡¬ç¼–ç ç»´åº¦
        # è®¡ç®—è¿‡ç¨‹: 256 â†’ 126 â†’ 62, é€šé“æ•°88
        # 62 * 62 * 88 = 338,272
        self.fully_connection = torch.nn.Linear(327448, 2)

    def forward(self, x):
        batch_size = x.size(0)

        # ç‰¹å¾æå–
        x = F.relu(self.pooling(self.conv1(x)))   # 256x256 â†’ 126x126
        x = self.inception1(x)                    # é€šé“: 10 â†’ 88

        x = F.relu(self.pooling(self.conv2(x)))   # 126x126 â†’ 62x62
        x = self.inception2(x)                    # é€šé“: 20 â†’ 88

        # å±•å¹³å¹¶å…¨è¿æ¥
        x = x.view(batch_size, -1)
        x = self.fully_connection(x)
        return x

# å®ä¾‹åŒ–æ¨¡å‹
net = Net().to(device)
print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼å‚æ•°é‡: {sum(p.numel() for p in net.parameters()):,}")


# In[33]:


# ==================== å•å…ƒæ ¼6ï¼šè®­ç»ƒå‡†å¤‡ ====================
# å…³é”®ä¿®æ”¹ï¼šç§»é™¤try-exceptï¼Œè®©é”™è¯¯æš´éœ²ï¼›æ˜¾å¼æ‰“å°ç»„ä»¶çŠ¶æ€

# æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·®ï¼ˆå›å½’ä»»åŠ¡ï¼‰
criterion = torch.nn.MSELoss()

# ä¼˜åŒ–å™¨ï¼šå¸¦åŠ¨é‡çš„SGD
optimizer = optim.SGD(
    net.parameters(), 
    lr=LEARNING_RATE, 
    momentum=0.5
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šæ¯15ä¸ªepochå­¦ä¹ ç‡å‡åŠ
scheduler = StepLR(optimizer, step_size=15, gamma=0.5)

print("âœ… è®­ç»ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆ:")
print(f"   æŸå¤±å‡½æ•°: {criterion}")
print(f"   ä¼˜åŒ–å™¨: SGD (lr={LEARNING_RATE}, momentum=0.5)")
print(f"   å­¦ä¹ ç‡è°ƒåº¦: StepLR (step=15, gamma=0.5)")


# In[34]:


# ==================== å•å…ƒæ ¼7ï¼šå·¥å…·å‡½æ•° ====================
# å…³é”®ä¿®æ”¹ï¼šç®€åŒ–è®¡ç®—é€»è¾‘ï¼Œæ·»åŠ è¯¦ç»†çš„è¿›åº¦æ‰“å°

def denormalize_targets(normalized_targets):
    """å°†å½’ä¸€åŒ–çš„æ ‡ç­¾è¿˜åŸåˆ°åŸå§‹å°ºåº¦"""
    play = np.expm1(normalized_targets[:, 0].cpu().numpy() * np.log1p(MAX_PLAY))
    like = np.expm1(normalized_targets[:, 1].cpu().numpy() * np.log1p(MAX_LIKE))
    return np.column_stack([play, like])

train_losses = []  # è®°å½•è®­ç»ƒæŸå¤±
test_losses = []   # è®°å½•æµ‹è¯•æŸå¤±

def train(epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    net.train()
    loss_aver = 0.0
    total_batches = len(train_loader)

    print(f"\nğŸš€ Epoch {epoch+1} è®­ç»ƒå¼€å§‹ (å…± {total_batches} ä¸ªbatch)")

    for batch_index, (inputs, labels) in enumerate(train_loader):
        # æ•°æ®ç§»è‡³GPU
        inputs, labels = inputs.to(device), labels.to(device)

        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()

        loss_aver += loss.item()

        # æ¯50ä¸ªbatchæ‰“å°ä¸€æ¬¡
        if (batch_index + 1) % 50 == 0:
            print(f'   [{batch_index+1:05d}/{total_batches}] loss: {loss_aver/50:.3f}')
            loss_aver = 0.0

    # è¿”å›å¹³å‡æŸå¤±
    return loss_aver / total_batches

def test(epoch):
    """æµ‹è¯•ä¸€ä¸ªepoch"""
    net.eval()
    total_mse, total_mae, total_samples = 0.0, 0.0, 0

    print(f"ğŸ“Š Epoch {epoch+1} æµ‹è¯•å¼€å§‹...")

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = net(inputs)

            # ç´¯ç§¯è¯¯å·®
            total_mse += F.mse_loss(outputs, labels, reduction='sum').item()
            total_mae += F.l1_loss(outputs, labels, reduction='sum').item()
            total_samples += labels.size(0)

    # è®¡ç®—å¹³å‡è¯¯å·®
    avg_mse = total_mse / total_samples
    avg_mae = total_mae / total_samples

    # æ‰“å°ç»“æœ
    print(f"   MSE: {avg_mse:.5f} | MAE: {avg_mae:.5f}")

    return avg_mse

def plot_loss_curve():
    """ç»˜åˆ¶æŸå¤±æ›²çº¿"""
    plt.figure(figsize=(12, 5))

    # MSEæ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss', marker='o')
    plt.plot(test_losses, label='Test Loss', marker='s')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.title('Training & Testing MSE')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # ä¿å­˜å›¾ç‰‡
    plt.savefig('./loss_curve.png', dpi=150, bbox_inches='tight')
    plt.show()
    print("ğŸ“ˆ æŸå¤±æ›²çº¿å·²ä¿å­˜è‡³ loss_curve.png")


# In[35]:


# ==================== å•å…ƒæ ¼8ï¼šä¸»è®­ç»ƒå¾ªç¯ ====================
# å…³é”®ä¿®æ”¹ï¼šåˆ é™¤ if __name__ == '__main__'ï¼Œç›´æ¥æ‰§è¡Œï¼›æ·»åŠ æœ€ä½³æ¨¡å‹ä¿å­˜

print("="*60)
print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
print(f"   Epochs: {EPOCHS} | Batch Size: {batch_size} | Device: {device}")
print("="*60)

best_loss = float('inf')  # æœ€ä½³æµ‹è¯•æŸå¤±
best_epoch = 0            # æœ€ä½³epoch

# è®­ç»ƒå¾ªç¯
for epoch in range(EPOCHS):
    # è®­ç»ƒ
    train_loss = train(epoch)

    # æµ‹è¯•
    test_loss = test(epoch)

    # è®°å½•æŸå¤±
    train_losses.append(train_loss)
    test_losses.append(test_loss)

    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step()
    current_lr = scheduler.get_last_lr()[0]
    print(f"   å­¦ä¹ ç‡å·²è°ƒæ•´ä¸º: {current_lr:.6f}")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if test_loss < best_loss:
        best_loss = test_loss
        best_epoch = epoch
        torch.save({
            'epoch': epoch,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': best_loss,
        }, MODEL_SAVE_PATH)
        print(f"   ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {epoch+1}, Loss: {best_loss:.5f})")

    # æ‰“å°åˆ†éš”çº¿
    print("-"*60)

# è®­ç»ƒç»“æŸ
print("\n" + "="*60)
print(f"ğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³Epoch: {best_epoch+1}, æœ€ä½³Loss: {best_loss:.5f}")
print("="*60)

# ç»˜åˆ¶æŸå¤±æ›²çº¿
plot_loss_curve()


# In[ ]:




