# %% [markdown]
# # ğŸ¯ è§†é¢‘å°é¢ â†’ æ’­æ”¾é‡ & ç‚¹èµæ•°ä¸‰åˆ†ç±»ï¼ˆä½ / ä¸­ / é«˜ï¼‰
# âœ… ä¸“ä¸ºä½ çš„æ•°æ®å®šåˆ¶ï¼š
#    - å›¾ç‰‡ç›®å½•: D:/å¤§ä½œä¸š/mydata/covers/
#    - CSV: D:/å¤§ä½œä¸š/mydata/result_no0.csv
#    - åˆ—å: filename, play_count, like_count
# âœ… å·²ä¿®å¤ Windows + CUDA æ‰€æœ‰é—®é¢˜

# %%
# ğŸ”§ ç¬¬ä¸€æ­¥ï¼šè®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¿…é¡»æ”¾åœ¨æœ€å‰ï¼ï¼‰
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# %%
# ğŸ”§ å¯¼å…¥åº“ï¼ˆç²¾ç®€ä¾èµ–ï¼‰
import os
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, recall_score
from sklearn.utils.class_weight import compute_class_weight
from tqdm import tqdm

# è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

# %% [markdown]
# ## ğŸ“‚ 1ï¸âƒ£ åŠ è½½ä½ çš„æ•°æ®ï¼ˆå·²æŒ‰ä½ çš„è·¯å¾„é…ç½®ï¼‰

# %%
# ğŸ”‘ ç›´æ¥ä½¿ç”¨ä½ çš„å®é™…è·¯å¾„
COVER_DIR = r"D:\bilitest\merged_data\covers"           # æ³¨æ„ï¼šç”¨ r"" é¿å…è½¬ä¹‰é—®é¢˜
METADATA_PATH = r"D:\bilitest\cleaned_data\result_no0.csv"

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(METADATA_PATH):
    raise FileNotFoundError(f"âŒ CSV ä¸å­˜åœ¨: {METADATA_PATH}")
print(f"âœ… æ‰¾åˆ° CSV: {METADATA_PATH}")

df = pd.read_csv(METADATA_PATH)
print(f"ğŸ“Œ åŸå§‹åˆ—å: {df.columns.tolist()}")
print(f"ğŸ“Œ æ€»æ ·æœ¬æ•°: {len(df)}")

# ğŸ”§ æŒ‰ä½ çš„åˆ—åæ˜ å°„ï¼ˆfilename, play_count, like_countï¼‰
df = df.rename(columns={
    'play_count': 'views',
    'like_count': 'likes'
})

# éªŒè¯å¿…è¦åˆ—
required = ['filename', 'views', 'likes']
missing = [col for col in required if col not in df.columns]
if missing:
    raise ValueError(f"âŒ CSV ç¼ºå°‘åˆ—: {missing}ï¼Œå½“å‰åˆ—: {df.columns.tolist()}")

print(f"âœ… åˆ—åæ˜ å°„æˆåŠŸ â†’ {df.columns.tolist()}")
print("\nğŸ“Š å‰3è¡Œæ•°æ®:")
print(df[['filename', 'views', 'likes']].head(3))

# %% [markdown]
# ## ğŸ“Š 2ï¸âƒ£ æ’­æ”¾é‡/ç‚¹èµæ•°åˆ†ç±»ï¼ˆlog10 + é‡çº§åˆ†ç®±ï¼‰

# %%
# å¯¹æ•°å˜æ¢ï¼ˆé¿å…è·¨åº¦å¤§é—®é¢˜ï¼‰
df['log_views'] = np.log10(df['views'] + 1)
df['log_likes'] = np.log10(df['likes'] + 1)

# âœ… é‡çº§åˆ†ç®±ï¼ˆæŒ‰å¸¸è§è§†é¢‘å¹³å°è°ƒæ•´ï¼‰
VIEWS_THRESH = [0, 5, 7, np.inf]   # ä½: <10ä¸‡, ä¸­: 10ä¸‡~1åƒä¸‡, é«˜: â‰¥1åƒä¸‡
LIKES_THRESH = [0, 4, 6, np.inf]   # ä½: <1ä¸‡, ä¸­: 1ä¸‡~100ä¸‡, é«˜: â‰¥100ä¸‡

df['views_class'] = pd.cut(df['log_views'], bins=VIEWS_THRESH, labels=['ä½', 'ä¸­', 'é«˜'], include_lowest=True)
df['likes_class'] = pd.cut(df['log_likes'], bins=LIKES_THRESH, labels=['ä½', 'ä¸­', 'é«˜'], include_lowest=True)

print("ğŸ“ˆ æ’­æ”¾é‡ç±»åˆ«åˆ†å¸ƒï¼š")
print(df['views_class'].value_counts().sort_index())
print("\nğŸ“ˆ ç‚¹èµæ•°ç±»åˆ«åˆ†å¸ƒï¼š")
print(df['likes_class'].value_counts().sort_index())

# è¾…åŠ©å‡½æ•°ï¼šæ˜¾ç¤ºå„ç±»åˆ«å®é™…èŒƒå›´
def show_class_range(df, class_col, value_col):
    print(f"\nğŸ” {class_col} å¯¹åº” {value_col} å®é™…èŒƒå›´ï¼š")
    for cls in ['ä½', 'ä¸­', 'é«˜']:
        subset = df[df[class_col] == cls][value_col]
        if len(subset) > 0:
            print(f"  {cls}: {subset.min():,} ~ {subset.max():,} (ä¸­ä½æ•°: {subset.median():,.0f})")

show_class_range(df, 'views_class', 'views')
show_class_range(df, 'likes_class', 'likes')

# %% [markdown]
# ## ğŸ–¼ï¸ 3ï¸âƒ£ æ•°æ®é¢„å¤„ç†ï¼ˆè·¯å¾„æ‹¼æ¥ + æŸåå›¾ç‰‡è¿‡æ»¤ï¼‰

# %%
# æ„å»ºå®Œæ•´è·¯å¾„ï¼ˆWindows è·¯å¾„å…¼å®¹ï¼‰
df['file_path'] = df['filename'].apply(lambda x: os.path.join(COVER_DIR, str(x)))

# æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
print("\nğŸ” æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å­˜åœ¨æ€§...")
missing_files = []
for idx, row in df.iterrows():
    if not os.path.exists(row['file_path']):
        missing_files.append(row['filename'])

if missing_files:
    print(f"âš ï¸ {len(missing_files)} å¼ å›¾ç‰‡ç¼ºå¤±ï¼Œä¾‹å¦‚: {missing_files[:3]}")
    df = df[df['file_path'].apply(os.path.exists)]
else:
    print("âœ… æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å­˜åœ¨")

# ç¼–ç ç±»åˆ«
le_views = LabelEncoder()
le_likes = LabelEncoder()
df['views_label'] = le_views.fit_transform(df['views_class'])
df['likes_label'] = le_likes.fit_transform(df['likes_class'])

print("\nğŸ”¤ ç±»åˆ«ç¼–ç æ˜ å°„ï¼š")
print("æ’­æ”¾é‡:", dict(zip(le_views.classes_, le_views.transform(le_views.classes_))))
print("ç‚¹èµæ•°:", dict(zip(le_likes.classes_, le_likes.transform(le_likes.classes_))))

# %%
# è‡ªå®šä¹‰ Datasetï¼ˆè‡ªåŠ¨è·³è¿‡æŸåå›¾ç‰‡ï¼‰
class CoverDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df.reset_index(drop=True)
        self.transform = transform
        self.valid_indices = []
        print("ğŸ” æ‰«ææœ‰æ•ˆå›¾ç‰‡ä¸­ï¼ˆè·³è¿‡æŸå/è¿‡å°å›¾ç‰‡ï¼‰...")
        for i, row in tqdm(self.df.iterrows(), total=len(self.df)):
            try:
                img = Image.open(row['file_path']).convert('RGB')
                if min(img.size) >= 20:  # è‡³å°‘ 20x20 åƒç´ 
                    self.valid_indices.append(i)
            except Exception as e:
                print(f"  è·³è¿‡: {row['filename']} â†’ {type(e).__name__}")
        print(f"âœ… æœ‰æ•ˆå›¾ç‰‡: {len(self.valid_indices)} / {len(self.df)}")

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx):
        real_idx = self.valid_indices[idx]
        row = self.df.iloc[real_idx]
        img = Image.open(row['file_path']).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, row['views_class'], row['likes_class']

# å›¾åƒå˜æ¢
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# åˆ’åˆ†æ•°æ®é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼‰
train_df, val_df = train_test_split(
    df,
    test_size=0.2,
    stratify=df[['views_class', 'likes_class']].apply(tuple, axis=1),
    random_state=42
)

train_dataset = CoverDataset(train_df, transform=train_transform)
val_dataset = CoverDataset(val_df, transform=val_transform)

# ğŸ”‘ å…³é”®ä¿®å¤ï¼šWindows ä¸‹ num_workers å¿…é¡»ä¸º 0ï¼
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)

print(f"\nğŸ§® è®­ç»ƒé›†: {len(train_dataset)} | éªŒè¯é›†: {len(val_dataset)}")

# %% [markdown]
# ## ğŸ§  4ï¸âƒ£ è½»é‡å¤šä»»åŠ¡æ¨¡å‹ï¼ˆMobileNetV2ï¼‰

# %%
class MultiTaskMobileNet(nn.Module):
    def __init__(self, num_views=3, num_likes=3):
        super().__init__()
        backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
        self.features = nn.Sequential(
            backbone.features,
            nn.AdaptiveAvgPool2d((1, 1))
        )
        self.views_head = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(1280, num_views)
        )
        self.likes_head = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(1280, num_likes)
        )

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        return self.views_head(x), self.likes_head(x)

model = MultiTaskMobileNet(
    num_views=len(le_views.classes_),
    num_likes=len(le_likes.classes_)
).to(device)
print("âœ… æ¨¡å‹: MobileNetV2 (è½»é‡é«˜æ•ˆï¼Œé€‚åˆä½ çš„æ•°æ®è§„æ¨¡)")

# %% [markdown]
# ## âš™ï¸ 5ï¸âƒ£ è®­ç»ƒè®¾ç½®ï¼ˆåŠ æƒæŸå¤±é˜²ä¸å¹³è¡¡ï¼‰

# %%
# ğŸ”‘ å¯¹å°‘æ•°ç±»åŠ æƒï¼ˆé«˜ç±»æ ·æœ¬æå°‘ï¼ï¼‰
weights_views = compute_class_weight(
    'balanced',
    classes=np.unique(train_df['views_label']),
    y=train_df['views_label']
)
weights_likes = compute_class_weight(
    'balanced',
    classes=np.unique(train_df['likes_label']),
    y=train_df['likes_label']
)

criterion_views = nn.CrossEntropyLoss(
    weight=torch.tensor(weights_views, dtype=torch.float).to(device)
)
criterion_likes = nn.CrossEntropyLoss(
    weight=torch.tensor(weights_likes, dtype=torch.float).to(device)
)

optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

EPOCHS = 12

# %%
def train_one_epoch(model, loader, crit_v, crit_l, optimizer, device):
    model.train()
    total_loss = 0.0
    for imgs, v_cls, l_cls in tqdm(loader, desc="è®­ç»ƒä¸­"):
        imgs = imgs.to(device, non_blocking=True)
        v_labels = torch.tensor(le_views.transform(v_cls), dtype=torch.long).to(device)
        l_labels = torch.tensor(le_likes.transform(l_cls), dtype=torch.long).to(device)

        optimizer.zero_grad()
        v_out, l_out = model(imgs)
        loss_v = crit_v(v_out, v_labels)
        loss_l = crit_l(l_out, l_labels)
        loss = loss_v + loss_l

        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def evaluate(model, loader, device, le_v, le_l):
    model.eval()
    v_true, v_pred = [], []
    l_true, l_pred = [], []
    
    with torch.no_grad():
        for imgs, v_cls, l_cls in tqdm(loader, desc="éªŒè¯ä¸­"):
            imgs = imgs.to(device, non_blocking=True)
            v_labels = le_v.transform(v_cls)
            l_labels = le_l.transform(l_cls)

            v_out, l_out = model(imgs)
            _, v_p = torch.max(v_out, 1)
            _, l_p = torch.max(l_out, 1)

            v_pred.extend(v_p.cpu().numpy())
            l_pred.extend(l_p.cpu().numpy())
            v_true.extend(v_labels)
            l_true.extend(l_labels)
    
    acc_v = accuracy_score(v_true, v_pred)
    acc_l = accuracy_score(l_true, l_pred)
    return acc_v, acc_l, v_true, v_pred, l_true, l_pred

# %% [markdown]
# ## â–¶ï¸ 6ï¸âƒ£ å¼€å§‹è®­ç»ƒï¼ˆè¿›åº¦æ¡åº”æ­£å¸¸æ»šåŠ¨ï¼ï¼‰

# %%
print("\nğŸ”¥ å¼€å§‹è®­ç»ƒï¼ˆbatch_size=8, num_workers=0, MobileNetV2ï¼‰...")
best_avg_acc = 0.0

for epoch in range(EPOCHS):
    loss = train_one_epoch(model, train_loader, criterion_views, criterion_likes, optimizer, device)
    acc_v, acc_l, _, _, _, _ = evaluate(model, val_loader, device, le_views, le_likes)
    avg_acc = (acc_v + acc_l) / 2

    print(f"Epoch {epoch+1:2d}/{EPOCHS} | Loss: {loss:.4f} | "
          f"Views Acc: {acc_v:.2%} | Likes Acc: {acc_l:.2%} | Avg: {avg_acc:.2%}")

    if avg_acc > best_avg_acc:
        best_avg_acc = avg_acc
        torch.save(model.state_dict(), r"D:\bilitest\modual\best_cover_model.pth")  # ä¿å­˜åˆ°ä½ çš„ç›®å½•
        print("   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹")

    scheduler.step()

# åŠ è½½æœ€ä½³æ¨¡å‹
model.load_state_dict(torch.load(r"D:\bilitest\modual\best_cover_model.pth", map_location=device))
print(f"\nğŸ† æœ€ä½³éªŒè¯å¹³å‡å‡†ç¡®ç‡: {best_avg_acc:.2%}")

# %% [markdown]
# ## ğŸ“ˆ 7ï¸âƒ£ è¯„ä¼°ç»“æœï¼ˆé‡ç‚¹å…³æ³¨é«˜ç±»å¬å›ç‡ï¼‰

# %%
acc_v, acc_l, v_true, v_pred, l_true, l_pred = evaluate(model, val_loader, device, le_views, le_likes)

print(f"\nâœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡ â†’ æ’­æ”¾é‡: {acc_v:.2%} | ç‚¹èµæ•°: {acc_l:.2%}")

# é«˜ç±»å¬å›ç‡ï¼ˆå…³é”®æŒ‡æ ‡ï¼ï¼‰
high_idx_v = list(le_views.classes_).index('é«˜')
high_idx_l = list(le_likes.classes_).index('é«˜')

high_recall_v = recall_score(v_true, v_pred, labels=[high_idx_v], average=None)[0]
high_recall_l = recall_score(l_true, l_pred, labels=[high_idx_l], average=None)[0]

print(f"\nğŸ¯ é«˜æ’­æ”¾é‡å¬å›ç‡: {high_recall_v:.2%} | é«˜ç‚¹èµå¬å›ç‡: {high_recall_l:.2%}")
print("ï¼ˆè¶Šé«˜è¶Šå¥½ï¼è¯´æ˜æ¨¡å‹èƒ½è¯†åˆ«çˆ†æ¬¾è§†é¢‘ï¼‰")

print("\nğŸ“Š æ’­æ”¾é‡åˆ†ç±»æŠ¥å‘Šï¼š")
print(classification_report(v_true, v_pred, target_names=le_views.classes_, digits=3))

print("\nğŸ“Š ç‚¹èµæ•°åˆ†ç±»æŠ¥å‘Šï¼š")
print(classification_report(l_true, l_pred, target_names=le_likes.classes_, digits=3))

# %% [markdown]
# ## ğŸ”® 8ï¸âƒ£ é¢„æµ‹æ–°å›¾ç‰‡ï¼ˆç¤ºä¾‹ï¼‰

# %%
def predict_cover(image_path, model, transform, device, le_v, le_l):
    """é¢„æµ‹å•å¼ å°é¢"""
    model.eval()
    try:
        img = Image.open(image_path).convert('RGB')
        img = transform(img).unsqueeze(0).to(device)
        
        with torch.no_grad():
            v_out, l_out = model(img)
            v_pred = torch.argmax(v_out, dim=1).item()
            l_pred = torch.argmax(l_out, dim=1).item()
        
        v_class = le_v.inverse_transform([v_pred])[0]
        l_class = le_l.inverse_transform([l_pred])[0]
        return v_class, l_class
    except Exception as e:
        return f"âŒ é”™è¯¯: {e}", ""

# ç¤ºä¾‹é¢„æµ‹ï¼ˆéªŒè¯é›†ç¬¬ä¸€å¼ ï¼‰
if len(val_df) > 0:
    sample = val_df.iloc[0]
    pred_v, pred_l = predict_cover(
        sample['file_path'], model, val_transform, device, le_views, le_likes
    )

    print(f"\nğŸ” ç¤ºä¾‹é¢„æµ‹ï¼š{sample['filename']}")
    print(f"   çœŸå® â†’ æ’­æ”¾é‡: {sample['views_class']}, ç‚¹èµ: {sample['likes_class']}")
    print(f"   é¢„æµ‹ â†’ æ’­æ”¾é‡: {pred_v}, ç‚¹èµ: {pred_l}")

    # å¯è§†åŒ–
    try:
        img = Image.open(sample['file_path']).convert('RGB')
        plt.figure(figsize=(4, 4))
        plt.imshow(img)
        plt.title(f"çœŸå®: {sample['views_class']}/{sample['likes_class']}\né¢„æµ‹: {pred_v}/{pred_l}", fontsize=12)
        plt.axis('off')
        plt.show()
    except Exception as e:
        print(f"âš ï¸ å›¾ç‰‡æ˜¾ç¤ºå¤±è´¥: {e}")

print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ä¸º: D:\bilitest\modual\best_cover_model.pth")