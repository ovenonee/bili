import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# ========================
# 1. åŠ è½½æ•°æ®
# ========================
df = pd.read_csv(r'D:\bilitest\cleaned_data\result_no0.csv')  # è¯·æ›¿æ¢ä¸ºä½ çš„ CSV æ–‡ä»¶å
# å‡è®¾åˆ—åæ˜¯: filename, play_count, like_count, label
print("åŸå§‹æ•°æ®å½¢çŠ¶:", df.shape)
print(df.head())

# åŠ è½½å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
visual_features = np.load(r'D:\bilitest\features\visual_X.npy')  # å½¢çŠ¶: (N, D1)
text_features = np.load(r'D:\bilitest\features\text_X.npy')      # å½¢çŠ¶: (N, D2)

assert len(df) == len(visual_features) == len(text_features), "æ ·æœ¬æ•°ä¸ä¸€è‡´ï¼"

# åˆå¹¶åŸºç¡€ç‰¹å¾
X = np.concatenate([visual_features, text_features], axis=1)

# ========================
# 2. åˆ›å»ºäº”åˆ†ç±»æ ‡ç­¾
# ========================
play_counts = df['play_count'].values

# ä½¿ç”¨åˆ†ä½æ•°åˆ’åˆ†äº”ç±»
q20 = np.percentile(play_counts, 20)
q40 = np.percentile(play_counts, 40)
q60 = np.percentile(play_counts, 60)
q80 = np.percentile(play_counts, 80)

def classify_hotness_5(pc):
    if pc < q20:
        return 'æä½çƒ­åº¦'
    elif pc < q40:
        return 'ä½çƒ­åº¦'
    elif pc < q60:
        return 'ä¸­çƒ­åº¦'
    elif pc < q80:
        return 'é«˜çƒ­åº¦'
    else:
        return 'æé«˜çƒ­åº¦'

hotness_labels = np.array([classify_hotness_5(pc) for pc in play_counts])
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(hotness_labels)

print(f"çƒ­åº¦åˆ’åˆ†é˜ˆå€¼:")
print(f"æä½(<{q20:.0f}), ä½({q20:.0f}~{q40:.0f}), ä¸­({q40:.0f}~{q60:.0f}), é«˜({q60:.0f}~{q80:.0f}), æé«˜(>{q80:.0f})")
print(f"çƒ­åº¦åˆ†å¸ƒ: {np.unique(hotness_labels, return_counts=True)}")

# ========================
# 3. ç‰¹å¾å·¥ç¨‹ï¼ˆæ·»åŠ å®‰å…¨ç‰¹å¾ï¼‰
# ========================
like_counts = df['like_count'].values

# ç‚¹èµ/æ’­æ”¾æ¯”ç‡
ratio_log = np.log1p(like_counts / (play_counts + 1e-8))

# åˆå¹¶ç‰¹å¾
X_enhanced = np.column_stack([
    X,                    # åŸå§‹å›¾åƒ+æ–‡æœ¬ç‰¹å¾
    ratio_log             # æ¯”ç‡ç‰¹å¾
])

print(f"å¢å¼ºåç‰¹å¾ç»´åº¦: {X_enhanced.shape[1]}")

# ========================
# 4. æ•°æ®é¢„å¤„ç†
# ========================
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_enhanced)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y, shuffle=True
)

# ========================
# 5. è®­ç»ƒXGBoostæ¨¡å‹
# ========================
try:
    from xgboost import XGBClassifier
    
    print("ğŸš€ ä½¿ç”¨ä¼˜åŒ–çš„ XGBoost æ¨¡å‹...")
    
    classifier = XGBClassifier(
        n_estimators=300,
        max_depth=10,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        random_state=42,
        objective='multi:softprob',
        eval_metric='mlogloss',
        n_jobs=1
    )
    
    print("å¼€å§‹è®­ç»ƒ XGBoost åˆ†ç±»å™¨...")
    classifier.fit(X_train, y_train)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    
    model_name = 'XGBoost_5Class'
    
except ImportError:
    print("âŒ æœªå®‰è£… xgboostï¼Œä½¿ç”¨éšæœºæ£®æ—")
    from sklearn.ensemble import RandomForestClassifier
    
    classifier = RandomForestClassifier(
        n_estimators=200,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        max_features='sqrt',
        random_state=42,
        n_jobs=1
    )
    
    print("å¼€å§‹è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨...")
    classifier.fit(X_train, y_train)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    
    model_name = 'RandomForest_5Class'

# ========================
# 6. è¯„ä¼°æ¨¡å‹
# ========================
y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')

print(f"\n=== æ¨¡å‹è¯„ä¼°ç»“æœ ({model_name}) ===")
print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
print(f"F1å®å¹³å‡: {f1_macro:.4f}")

target_names = label_encoder.classes_
print("\n=== è¯¦ç»†åˆ†ç±»æŠ¥å‘Š ===")
print(classification_report(y_test, y_pred, target_names=target_names))

cm = confusion_matrix(y_test, y_pred)
print("\n=== æ··æ·†çŸ©é˜µ ===")
print(cm)

# ========================
# 7. å¯è§†åŒ–ç»“æœ
# ========================
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names, yticklabels=target_names)
plt.title(f'{model_name} æ··æ·†çŸ©é˜µ')
plt.xlabel('é¢„æµ‹æ ‡ç­¾')
plt.ylabel('çœŸå®æ ‡ç­¾')
plt.tight_layout()
plt.show()

# ========================
# 8. ä¿å­˜æ¨¡å‹
# ========================
joblib.dump(classifier, f'bilibili_classifier_{model_name.lower()}.pkl')
joblib.dump(label_encoder, 'label_encoder_5class.pkl')
joblib.dump(scaler, 'feature_scaler_5class.pkl')
print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜ä¸º 'bilibili_classifier_{model_name.lower()}.pkl'")

# ========================
# 9. ç¤ºä¾‹é¢„æµ‹
# ========================
print("\n=== ç¤ºä¾‹é¢„æµ‹ ===")
y_pred_proba = classifier.predict_proba(X_test)
sample_idx = np.random.choice(len(X_test), 5, replace=False)

for i, idx in enumerate(sample_idx):
    true_label = label_encoder.inverse_transform([y_test[idx]])[0]
    pred_label = label_encoder.inverse_transform([y_pred[idx]])[0]
    prob = y_pred_proba[idx]
    prob_str = ", ".join([f"{name}:{p:.2f}" for name, p in zip(target_names, prob)])
    print(f"æ ·æœ¬ {i+1}: çœŸå®={true_label}, é¢„æµ‹={pred_label}, æ¦‚ç‡=[{prob_str}]")

# ========================
# 10. äº¤å‰éªŒè¯è¯„ä¼°
# ========================
print("\nğŸ” è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯è¯„ä¼°...")
cv_scores = cross_val_score(
    classifier, 
    X_scaled, y, 
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring='f1_macro',
    n_jobs=1
)

print(f"5æŠ˜äº¤å‰éªŒè¯F1å®å¹³å‡åˆ†æ•°: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# ========================
# 11. æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡
# ========================
from sklearn.metrics import precision_recall_fscore_support

precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)
print("\n=== å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡ ===")
for i, class_name in enumerate(target_names):
    print(f"{class_name}: P={precision[i]:.3f}, R={recall[i]:.3f}, F1={f1[i]:.3f}, Support={support[i]}")

# ========================
# 12. éšæœºçŒœæµ‹åŸºå‡†
# ========================
n_classes = len(np.unique(y))
random_accuracy = 1.0 / n_classes
print(f"\n=== åŸºå‡†æ¯”è¾ƒ ===")
print(f"éšæœºçŒœæµ‹å‡†ç¡®ç‡: {random_accuracy:.4f}")
print(f"æ¨¡å‹å‡†ç¡®ç‡æå‡: {accuracy - random_accuracy:.4f}")