# bili_final_crawler.py
import requests
import time
import os
import pandas as pd
import urllib.parse
import random
from tqdm import tqdm

# ==================== ÂÖ®Â±ÄÈÖçÁΩÆÂå∫ÔºàÁî®Êà∑ÈúÄ‰øÆÊîπÔºâ ====================
# ‰ªéÊµèËßàÂô®F12Ëé∑ÂèñÁöÑÂÆåÊï¥CookieÔºàËøáÊúüÈúÄÊõ¥Êñ∞Ôºâ
COOKIE = 'buvid3=D5B97EBF-167B-3A7D-04B6-2C016C151A0331350infoc; b_nut=1753971030; i-wanna-go-back=-1; _uuid=CE910272B-9962-93EF-D4F7-C8D516E104C4E47670infoc; FEED_LIVE_VERSION=V8'

# ÂÖ≥ÈîÆËØçÊ±†Ôºà24‰∏™ÂÖ≥ÈîÆËØçÔºåÂèØÊâ©Â±ïÔºâ
KEYWORD_POOL = [
    "ÊêûÁ¨ë", "ÁæéÈ£ü", "Â≠¶‰π†", "ËêåÂÆ†", "Ê∏∏Êàè", "ÁßëÊäÄ", "ÂÅ•Ë∫´", "Èü≥‰πê",
    "ËàûËπà", "ÁîµÂΩ±", "Âä®Êº´", "ÊêûÁ¨ë", "ÊâãÂ∑•", "ÊëÑÂΩ±", "Á©øÊê≠", "ÁæéÂ¶Ü",
    "Ê±ΩËΩ¶", "ËÅåÂú∫", "ÂøÉÁêÜÂ≠¶", "ÂéÜÂè≤", "Ê≥ïÂæã", "ËÇ≤ÂÑø", "Ë£Ö‰øÆ", "Âõ≠Ëâ∫"
]
# ============================================================

def crawl_bilibili_videos(target_total=10000, pages_per_keyword=30):
    """
    BÁ´ôÂ§ßËßÑÊ®°ËßÜÈ¢ëÁà¨Ëô´
    
    ÂèÇÊï∞Ôºö
        target_total: ÁõÆÊ†áÁà¨ÂèñÊï∞ÈáèÔºàÈªòËÆ§10000Ôºâ
        pages_per_keyword: ÊØè‰∏™ÂÖ≥ÈîÆËØçÁà¨ÂèñÈ°µÊï∞ÔºàÊé®Ëçê30È°µÔºâ
    """
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'application/json, text/plain, */*',
        'Cookie': COOKIE,
    }
    
    os.makedirs('covers', exist_ok=True)
    data_file = 'video_data_final.csv'
    
    # Êñ≠ÁÇπÁª≠‰º†
    if os.path.exists(data_file):
        existing_df = pd.read_csv(data_file)
        last_index = existing_df['filename'].astype(int).max() if len(existing_df) > 0 else 0
        all_data = existing_df.to_dict('records')
        print(f"üìÇ Âä†ËΩΩÂ∑≤ÊúâÊï∞ÊçÆ: {len(existing_df)} Êù°ÔºåÊúÄÂêéÁºñÂè∑: {last_index}.jpg")
    else:
        all_data = []
        last_index = 0
        print(f"üÜï Êñ∞‰ªªÂä°ÔºåÁõÆÊ†á: {target_total} Êù°")
    
    current_index = last_index
    if current_index >= target_total:
        print(f"‚úÖ ÁõÆÊ†áÂ∑≤ËææÊàêÔºÅÂΩìÂâç: {current_index} Êù°")
        return pd.DataFrame(all_data)
    
    print(f"üéØ ÊÄªÈáè: {target_total} | ËøòÈúÄ: {target_total - current_index}")
    
    # ‰∏ªÂæ™ÁéØ
    for keyword in KEYWORD_POOL:
        if current_index >= target_total:
            break
        
        print(f"\n{'='*50}")
        print(f"üîç {keyword} | ËøõÂ∫¶: {current_index}/{target_total}")
        print(f"{'='*50}")
        
        for page in tqdm(range(1, pages_per_keyword + 1), desc=f"{keyword:>6s}", ncols=80):
            if current_index >= target_total:
                break
            
            # È°µÈó¥Âª∂Ëøü
            page_delay = random.uniform(5, 8)
            print(f"‚è≥ È°µ{page:>3d}Á≠âÂæÖ: {page_delay:.1f}s")
            time.sleep(page_delay)
            
            try:
                url = f"https://api.bilibili.com/x/web-interface/search/type?search_type=video&keyword={urllib.parse.quote(keyword)}&page={page}"
                response = requests.get(url, headers=headers, timeout=20)
                
                if response.status_code == 412:
                    print(f"\n‚ö†Ô∏è Ëß¶Âèë412ÂèçÁà¨ÔºåÊöÇÂÅú10ÂàÜÈíü...")
                    time.sleep(600)
                    continue
                elif response.status_code != 200:
                    print(f"\n‚ùå Áä∂ÊÄÅÁ†Å: {response.status_code}")
                    time.sleep(10)
                    continue
                
                json_data = response.json()
                
                if json_data.get('code') != 0:
                    print(f"\n‚ùå APIÈîôËØØ: {json_data.get('message')}")
                    break
                
                videos = json_data['data'].get('result', [])
                print(f"üì¶ Êú¨È°µËøîÂõû {len(videos)} ‰∏™ËßÜÈ¢ë")
                
                success_count = 0
                fail_count = 0
                
                for video in videos:
                    if current_index >= target_total:
                        break
                    
                    try:
                        # URLÂ§ÑÁêÜ
                        pic_url = video.get('pic', '').strip()
                        if not pic_url:
                            fail_count += 1
                            continue
                        
                        if isinstance(pic_url, list):
                            pic_url = pic_url[0] if pic_url else ''
                        
                        if pic_url.startswith('//'):
                            cover_url = 'https:' + pic_url
                        elif pic_url.startswith('/bfs/'):
                            cover_url = 'https://i0.hdslb.com' + pic_url
                        elif pic_url.startswith('http://'):
                            cover_url = pic_url.replace('http://', 'https://')
                        else:
                            cover_url = pic_url
                        
                        if not cover_url.startswith('https://'):
                            fail_count += 1
                            continue
                        
                        # ‰∏ãËΩΩ
                        download_delay = random.uniform(1, 2)
                        time.sleep(download_delay)
                        
                        img_response = requests.get(cover_url, timeout=15, headers={'User-Agent': headers['User-Agent']})
                        
                        if img_response.status_code != 200:
                            fail_count += 1
                            continue
                        
                        if len(img_response.content) < 1024:
                            fail_count += 1
                            continue
                        
                        current_index += 1
                        filename = f"{current_index}.jpg"
                        with open(f'covers/{filename}', 'wb') as f:
                            f.write(img_response.content)
                        
                        # CSVÁ≤æÁÆÄ
                        all_data.append({
                            'filename': filename,
                            'play_count': int(video.get('play', 0)),
                            'like_count': int(video.get('like', 0))
                        })
                        
                        success_count += 1
                        
                        # ÊØè10Êù°‰øùÂ≠ò
                        if current_index % 10 == 0:
                            df_temp = pd.DataFrame(all_data)
                            df_temp.to_csv(data_file, index=False)
                            print(f"\nüíæ Ëá™Âä®‰øùÂ≠ò: {current_index}/{target_total} ({current_index/target_total*100:.1f}%)")
                        
                    except Exception as e:
                        fail_count += 1
                        print(f"  ‚ùå {type(e).__name__}: {str(e)[:30]}")
                        continue
                
                print(f"üìÑ Á¨¨{page}È°µ: ‚úì{success_count} ‚úó{fail_count}")
                
            except Exception as e:
                print(f"\n‚ùå È°µËØ∑Ê±ÇÂ§±Ë¥•: {type(e).__name__}")
                time.sleep(10)
                continue
        
        if current_index < target_total:
            batch_delay = random.uniform(300, 400)
            print(f"\n‚òï ‰ºëÊÅØ {batch_delay/60:.1f} ÂàÜÈíü...")
            time.sleep(batch_delay)
    
    # ÊúÄÁªàÂº∫Âà∂‰øùÂ≠ò
    if all_data:
        df_final = pd.DataFrame(all_data)
        df_final.to_csv(data_file, index=False)
        print(f"\nüíæ ÊúÄÁªàCSVÂ∑≤‰øùÂ≠ò: {os.path.abspath(data_file)}")
        print(f"üìä ÂåÖÂê´ {len(df_final)} Êù°Êï∞ÊçÆ")
    else:
        print("‚ö†Ô∏è Êó†Êï∞ÊçÆÂèØ‰øùÂ≠ò")
    
    return df_final

# ==================== ËøêË°åÂÖ•Âè£ ====================
if __name__ == "__main__":
    print("üöÄ ÂêØÂä®BÁ´ôÁà¨Ëô´ÔºàÂÆåÊï¥‰øÆÂ§çÁâàÔºâ")
    print("="*50)
    
    # ÈÖçÁΩÆÂèÇÊï∞ÔºàÁî®Êà∑ÂèØ‰øÆÊîπÔºâ
    TARGET = 10000      # ÁõÆÊ†áÊï∞Èáè
    PAGES_PER_KEYWORD = 30  # ÊØè‰∏™ÂÖ≥ÈîÆËØçÈ°µÊï∞
    
    # È¢Ñ‰º∞‰ø°ÊÅØ
    estimated_total = len(KEYWORD_POOL) * PAGES_PER_KEYWORD * 16  # Êåâ80%ÊàêÂäüÁéá‰º∞ÁÆó
    print(f"üìà ÂÖ≥ÈîÆËØçÊï∞: {len(KEYWORD_POOL)}")
    print(f"üìÑ ÊØèÂÖ≥ÈîÆËØçÈ°µÊï∞: {PAGES_PER_KEYWORD}")
    print(f"üìä È¢Ñ‰º∞ÊÄªÈáè: {estimated_total} Êù°")
    print(f"üéØ ÂÆûÈôÖÁõÆÊ†á: {TARGET} Êù°")
    print("="*50)
    
    # ÊâßË°åÁà¨Âèñ
    data = crawl_bilibili_videos(
        target_total=TARGET,
        pages_per_keyword=PAGES_PER_KEYWORD
    )
    
    # ÁªüËÆ°Êä•Âëä
    if not data.empty:
        print("\n" + "="*50)
        print("üìà Áà¨ÂèñÁªüËÆ°")
        print("="*50)
        print(f"‚úÖ ÊàêÂäü: {len(data)} Êù°")
        print(f"üíæ CSVË∑ØÂæÑ: {os.path.abspath('video_data_final.csv')}")
        print(f"üìÅ Â∞ÅÈù¢Ë∑ØÂæÑ: {os.path.abspath('covers/')}")
        print(f"üìä Êï∞ÊçÆÈ¢ÑËßà:\n{data.head()}")
        print("="*50)
        print("\n‚úÖ ‰ªªÂä°ÂÆåÊàêÔºÅ")
